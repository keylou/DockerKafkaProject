// updating an orders discounts and payments in an online store
// Кафка независимая сущность. Я - автор программы - ее пользователь.
// Кафка потоки состоят из трех сущностей:
// 1) source - источник - выдает элементы определенного типа.
// 2) flow - обработчик - преобразует элементы.
// 3) sink - потребитель - забирает элементы.
// Поток - серия токенов, генерируемые источником, трансформируемые обработчиком и забираемые потребителем.
// KStream - поток элементов из кафка топика. Стандарт. KStream[K, V] ключ-значение.
// KTable - аналог KStream, но элементы более статичны, хранятся в топике, поддерживаются брокером. Распределены по кафка нодам.
// GlobalKTable - скопирован во все ноды. Хранит немного значений, чтобы не превысить лимит нод.
// Удобно подмешивать в него KTable, так как нодам не придется друг друга искать.
// Брокер не удаляет сообщения при "cleanup.policy=compact" по времени жизни. (используется у KTable и GlobalKTable)
// Есть преобразования с сохранением состояния и без:
// Stateless = map, filter, flatMap, count, windowed aggregations etc.
// Stateful = join, aggregations
// Windowed aggregations - позволяют агрегировать сообщение за какое-то временное окно.
// Кафка позволяет джойнить не только Stream-Table (динамическое и статическое), но и Stream-Stream
// Для этого нужно окно, которое будет позволять им джойниться, иначе результирующий поток будет бесконечно разрастаться.

import io.circe.generic.auto._
import io.circe.parser._
import io.circe.syntax._
import io.circe.{Decoder, Encoder}
import org.apache.kafka.common.serialization.Serde
import org.apache.kafka.streams.kstream.{GlobalKTable, JoinWindows, TimeWindows, Windowed}
import org.apache.kafka.streams.scala.ImplicitConversions._
import org.apache.kafka.streams.scala._
import org.apache.kafka.streams.scala.kstream.{KGroupedStream, KStream, KTable}
import org.apache.kafka.streams.scala.serialization.Serdes
import org.apache.kafka.streams.scala.serialization.Serdes._
import org.apache.kafka.streams.{KafkaStreams, StreamsConfig, Topology}

import java.time.Duration
import java.util.Properties
import scala.concurrent.duration._

object KafkaStreams {

  object Domain {
    type UserId = String
    type Profile = String
    type Product = String
    type OrderId = String
    type Status = String

    case class Order(orderId: OrderId, userId: UserId, products: List[Product], amount: Double)

    case class Discount(profile: Profile, amount: Double)

    case class Payment(orderId: OrderId, status: Status)
  }

  object Topics {
    final val OrdersByUserTopic = "orders-by-user"
    final val DiscountProfilesByUserTopic = "discount-profiles-by-user"
    final val DiscountsTopic = "discounts"
    final val OrdersTopic = "orders"
    final val PaymentsTopic = "payments"
    final val PaidOrdersTopic = "paid-orders"
  }

  import Domain._
  import Topics._

  implicit def serde[A >: Null : Decoder : Encoder]: Serde[A] = { // The interface for wrapping a serializer and deserializer for the given data type.
    val serializer = (entity: A) => entity.asJson.noSpaces.getBytes
    val deserializer = (bytes: Array[Byte]) => {
      val string = new String(bytes)
      val maybeEntity = decode[A](string)
      maybeEntity match {
        case Right(value) => Option(value)
        case Left(error) =>
          println(s"There was an error converting the message $maybeEntity, $error")
          Option.empty
      }
    }

    Serdes.fromFn[A](serializer, deserializer)
  }

  def main(args: Array[String]): Unit = {

    val builder = new StreamsBuilder()
    val usersOrdersStreams: KStream[UserId, Order] = builder.stream[UserId, Order](OrdersByUserTopic)
    val userProfilesTable: KTable[UserId, Profile] = builder.table[UserId, Profile](DiscountProfilesByUserTopic)
    val discountProfilesGTable: GlobalKTable[Profile, Discount] = builder.globalTable[Profile, Discount](DiscountsTopic)

    val expensiveOrders: KStream[UserId, Order] = usersOrdersStreams.filter { (userId, order) =>
      order.amount > 1000
    }

    val purchasedProductsStream: KStream[UserId, Product] = usersOrdersStreams.flatMapValues { order =>
      order.products
    }

    val purchasedListOfProductsStream: KStream[UserId, List[Product]] = usersOrdersStreams.mapValues { order =>
      order.products
    }

    val productsPurchasedByUsers: KGroupedStream[UserId, Product] = purchasedProductsStream.groupByKey

    val numberOfProductsByUser: KTable[UserId, Long] = productsPurchasedByUsers.count()

    purchasedProductsStream.foreach { (userId, product) =>
      println(s"The user $userId purchased the product $product")
    }

    // Опасная операция, так как мы меняем ключ, что может повлечь перераспределение сообщений на другую ноду => большая нагрузка на сеть.
    val purchasedByFirstLetter: KGroupedStream[String, Product] =
      purchasedProductsStream.groupBy[String] { (userId, products) =>
        userId.charAt(0).toLower.toString
      }

    // Добавление сообщений потока в новый топик
    expensiveOrders.to("suspicious-orders")

    // fixed-size, non-overlapping, gapless
    val everyTenSeconds: TimeWindows = TimeWindows.of(Duration.ofSeconds(10))

    val numberOfProductsByUserEveryTenSeconds: KTable[Windowed[UserId], Long] =
      productsPurchasedByUsers.windowedBy(everyTenSeconds)
        .aggregate[Long](0L) { (userId, product, counter) =>
          counter + 1
        }

    val ordersWithUserProfileStream: KStream[UserId, (Order, Profile)] =
      usersOrdersStreams.join[Profile, (Order, Profile)](userProfilesTable) { (order, profile) =>
        (order, profile)
      }

    val discountedOrdersStream: KStream[UserId, Order] =
      ordersWithUserProfileStream.join[Profile, Discount, Order](discountProfilesGTable)(
        { case (_, (_, profile)) => profile }, // Joining key from ordersWithUserProfileStream
        { case ((order, _), discount) => order.copy(amount = order.amount * discount.amount) }
      )

    val ordersStream = discountedOrdersStream.selectKey((userId, order) => order.orderId)

    val paymentsStream = builder.stream[OrderId, Payment](PaymentsTopic)

    val joinWindow = JoinWindows.of(Duration.ofMinutes(5))

    val ordersPaid = ordersStream.join(paymentsStream)({ (order, payment) =>
        (order, payment) match {
          case (order, payment) if payment.status == "PAID" => Option(order)
          case _ => None
        }
      }, joinWindow)
      .flatMapValues(maybeOrder => maybeOrder.toList)

    ordersPaid.to(PaidOrdersTopic)

    val topology = builder.build()

    val props = new Properties

    props.put(StreamsConfig.APPLICATION_ID_CONFIG, "orders-application")
    props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092")
    props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.stringSerde.getClass)

    //println(topology.describe())

    val application = new KafkaStreams(topology, props)
    application.start()
  }
}
